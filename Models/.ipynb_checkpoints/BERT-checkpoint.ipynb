{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/waihengsoh/Desktop/Simply Solution/vehicle_dis/Equities_Price_Prediction_XAI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from Functions.Historical_News import historical_news\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 18:13:20.767168: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "Error getting the news\n",
      "\"None of [Index(['date', 'content'], dtype='object')] are in the [columns]\"\n",
      "4340 4340 1085 1085\n"
     ]
    }
   ],
   "source": [
    "news = historical_news.get_all_news(date(2021, 10, 1), date(2022, 10, 1))\n",
    "news = news.loc[:, ['content', 'price_change']]\n",
    "X = news['content'].tolist()\n",
    "y = news['price_change'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(len(X_train), len(y_train), len(X_test), len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(news, test_size=0.2, random_state=42)\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_example_to_feature(review):\n",
    "  return tokenizer.encode_plus(review,\n",
    "                add_special_tokens = True, # add [CLS], [SEP]\n",
    "                max_length = 512, # max length of the text that can go to BERT\n",
    "                pad_to_max_length = True, # add [PAD] tokens\n",
    "                return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
    "  return {\n",
    "      \"input_ids\": input_ids,\n",
    "      \"token_type_ids\": token_type_ids,\n",
    "      \"attention_mask\": attention_masks,\n",
    "  }, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_examples(ds, limit=-1):\n",
    "  # prepare list, so that we can build up final TensorFlow dataset from slices.\n",
    "  input_ids_list = []\n",
    "  token_type_ids_list = []\n",
    "  attention_mask_list = []\n",
    "  label_list = []\n",
    "  if (limit > 0):\n",
    "      ds = ds.take(limit)\n",
    "  for review, label in ds.to_numpy():\n",
    "    bert_input = convert_example_to_feature(review)\n",
    "    input_ids_list.append(bert_input['input_ids'])\n",
    "    token_type_ids_list.append(bert_input['token_type_ids'])\n",
    "    attention_mask_list.append(bert_input['attention_mask'])\n",
    "    label_list.append([label])\n",
    "  return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "# train dataset\n",
    "ds_train_encoded = encode_examples(train).shuffle(10000).batch(batch_size)\n",
    "# test dataset\n",
    "ds_test_encoded = encode_examples(test).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 1\n",
    "bert_history = model.fit(ds_train_encoded, epochs=number_of_epochs, validation_data=ds_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"terrible\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input = tokenizer.encode(test_sentence,\n",
    "\n",
    "truncation=True,\n",
    "\n",
    "padding=True,\n",
    "\n",
    "return_tensors=\"tf\")\n",
    "\n",
    "tf_output = model.predict(predict_input)[0]\n",
    "tf_prediction = tf.nn.softmax(tf_output, axis=1)\n",
    "print(tf_prediction)\n",
    "labels = ['Negative','Positive'] #(0:negative, 1:positive)\n",
    "label = tf.argmax(tf_prediction, axis=1)\n",
    "label = label.numpy()\n",
    "print(labels[label[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31123794a318c38813355d29e032308f1989c1650d27ec22783ecd4e025c111f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
